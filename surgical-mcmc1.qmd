---
title: "Surgical - 1er exemple"
format: pdf
editor: visual
---

```{r}
library(coda) #pour fonction mcmc
```

Pour un hôpital $i$, on a :

-   $n_i$ : le nombre d'opérations

-   $p_i$ : la proba de mourir

-   $r_i$ : le nombre de morts

$r_i | p_i \sim B(p_i,n_i)$

$p_i \sim Beta(1,1)$

Après calcul de la loi à posteriori :

$\pi(p_i, r_i) \propto Beta(1+r_i, 1+n_i - r_i)$

On implémente un algorithme de Gibbs :

```{r}
gibbs1 = function(nchain){
  #nombres d'opération
  n_ops = c(47, 148, 119, 810,   211, 196, 148, 215, 207, 97, 256, 360)
  #nombre de morts par hopital
  n_death = c(0, 18, 8, 46, 8, 13, 9,   31, 14, 8, 29, 24)
  #nombre d'hopitaux
  N_hospitals = 12 
  
  chain = matrix(0.5, nchain + 1, N_hospitals) #p1, ..., p12
  colnames(chain) = c(paste0("p",1:12))
  
  for (i in 1:nchain){
    pi = chain[i,]
    #pour chaque hopital (N)
    for (j in 1:N_hospitals){
      pi[j] = rbeta(1, n_death[j]+1, n_ops[j] - n_death[j] +1)
    }
    #stocker les valeurs de la chaine
    chain[i+1,] = pi 
  }
  return(chain)
}
```

On peut afficher nos chaînes de Markov avec les densités associées :

```{r}
chain = gibbs1(11000)

#burn in period
chain = chain[1001:11001,]
plot(mcmc(chain))
```

```{r}
plot(chain[,2], xlab="", ylab="", col="blue", type="l")
```

Ainsi que les autocorrélations pour chaque paramètres :

```{r}
for (i in 1:12) {
  acf(chain[,i], main=paste0("p[",i,"]"))
}
```

Enfin, on peut avoir les estimations des moyennes et écart-types de nos paramètres :

```{r}
res = data.frame(
  mean = round(apply(chain, 2, mean), 4),
  sd = round(apply(chain, 2, sd), 4),
  q2.5 = apply(chain, 2, function(x) quantile(x,probs=0.025)),
  q97.5 = apply(chain, 2, function(x) quantile(x,probs=0.975))
)
rownames(res) = paste0("p[", 1:12,"]")
print(res)
```
